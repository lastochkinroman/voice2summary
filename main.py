import os
import asyncio
import uuid
import logging
from pathlib import Path
from datetime import datetime

import aiofiles
import requests
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes
from mistralai.client import MistralClient
from pydub import AudioSegment

from config import Config

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)
mistral_client = MistralClient(api_key=Config.MISTRAL_API_KEY)
Path(Config.TEMP_DIR).mkdir(exist_ok=True)


class AudioProcessor:

    @staticmethod
    async def download_audio(file_url: str, file_path: str):
        try:
            response = requests.get(file_url)
            response.raise_for_status()

            async with aiofiles.open(file_path, 'wb') as f:
                await f.write(response.content)

            logger.info(f"Audio downloaded: {file_path}")
            return True
        except Exception as e:
            logger.error(f"Error downloading audio: {e}")
            return False

    @staticmethod
    async def convert_to_wav(input_path: str, output_path: str):
        try:
            filename, file_extension = os.path.splitext(input_path)
            file_extension = file_extension.lower()
            
            if file_extension == '.ogg':
                import shutil
                shutil.copy(input_path, output_path)
                logger.info(f"Audio copied (no conversion needed): {output_path}")
                return True
                
            import subprocess
            import sys
            
            ffmpeg_cmd = [
                Config.FFMPEG_PATH,
                "-i", input_path,
                "-ar", "16000",
                "-ac", "1",
                "-sample_fmt", "s16",
                output_path
            ]
            
            result = subprocess.run(
                ffmpeg_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                shell=True
            )
            
            if result.returncode != 0:
                logger.error(f"FFmpeg conversion error: {result.stderr.decode('cp1251')}")
                return False
                
            logger.info(f"Audio converted: {output_path}")
            return True
        except Exception as e:
            logger.error(f"Error converting audio: {e}")
            return False


class SpeechRecognizer:

    def __init__(self):
        self.api_url = Config.SALUTE_SPEECH_URL
        self.oauth_url = Config.SALUTE_SPEECH_OAUTH_URL
        self.auth_key = Config.SALUTE_SPEECH_AUTH_KEY
        self.scope = Config.SALUTE_SPEECH_SCOPE
        self.access_token = None
        self.token_expires_at = 0

    async def _get_access_token(self) -> str:
        try:
            current_time = datetime.now().timestamp() * 1000
            if self.access_token and (self.token_expires_at - current_time) > 60000:
                return self.access_token

            headers = {
                'Content-Type': 'application/x-www-form-urlencoded',
                'Accept': 'application/json',
                'RqUID': str(uuid.uuid4()),
                'Authorization': f'Basic {self.auth_key}'
            }

            data = {
                'scope': self.scope
            }

            response = requests.post(
                self.oauth_url,
                headers=headers,
                data=data,
                verify=False
            )
            response.raise_for_status()
            result = response.json()

            self.access_token = result.get('access_token')
            self.token_expires_at = result.get('expires_at')

            logger.info("–ü–æ–ª—É—á–µ–Ω –Ω–æ–≤—ã–π Access Token")
            return self.access_token
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è Access Token: {e}")
            raise

    async def recognize(self, audio_file_path: str) -> str:
        try:
            token = await self._get_access_token()

            with open(audio_file_path, 'rb') as audio_file:
                audio_data = audio_file.read()

            filename, file_extension = os.path.splitext(audio_file_path)
            file_extension = file_extension.lower()
            
            if file_extension == '.ogg':
                headers = {
                    'Content-Type': 'audio/ogg;codecs=opus',
                    'Authorization': f'Bearer {token}',
                    'X-Request-ID': str(uuid.uuid4())
                }
            elif file_extension == '.wav' or file_extension == '.pcm':
                headers = {
                    'Content-Type': 'audio/x-pcm;bit=16;rate=16000',
                    'Authorization': f'Bearer {token}',
                    'X-Request-ID': str(uuid.uuid4())
                }
            elif file_extension == '.mp3':
                headers = {
                    'Content-Type': 'audio/mpeg',
                    'Authorization': f'Bearer {token}',
                    'X-Request-ID': str(uuid.uuid4())
                }
            else:
                logger.error(f"Unsupported audio format: {file_extension}")
                return ""

            response = requests.post(
                self.api_url,
                headers=headers,
                data=audio_data,
                verify=False
            )
            response.raise_for_status()
            result = response.json()
            text = result.get('result', '')
            logger.info(f"Speech recognized: {len(text)} characters")
            return text
        except Exception as e:
            logger.error(f"Speech recognition error: {e}")
            return ""


class MeetingAnalyzer:

    async def analyze_meeting(self, transcript: str) -> str:
        try:
            prompt = f"""
            –¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–µ–ª–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –≤—Å—Ç—Ä–µ—á–∏ –∏ —Å–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ.

            –¢–µ–∫—Å—Ç –≤—Å—Ç—Ä–µ—á–∏:
            {transcript}

            –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:
            1. –£—á–∞—Å—Ç–Ω–∏–∫–∏ –≤—Å—Ç—Ä–µ—á–∏ (–∫—Ç–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª)
            2. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è
            3. –ü—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥—ã
            4. –ù–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ (—á—Ç–æ, –∫—Ç–æ, —Å—Ä–æ–∫–∏)
            5. –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –∏ –¥–∞—Ç–∞ —Å–ª–µ–¥—É—é—â–µ–π –≤—Å—Ç—Ä–µ—á–∏

            –ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º –∏ –≤—ã–¥–µ–ª—è–π —Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ.

            –Ω–µ —Å–æ—Å—Ç–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö —Ç–∞–±–ª–∏—Ü
            """

            response = mistral_client.chat(
                model="mistral-medium",
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–µ–ª–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á. –¢—ã —Å–æ–∑–¥–∞–µ—à—å —á–µ—Ç–∫–∏–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ."
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3
            )

            analysis = response.choices[0].message.content
            logger.info("Meeting analysis completed")
            return analysis

        except Exception as e:
            logger.error(f"AI analysis error: {e}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–µ—á—É."


async def handle_audio_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    message = update.message
    await message.reply_text("üé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à–µ –∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        audio_id = f"{user.id}_{timestamp}"
        original_file = os.path.join(Config.TEMP_DIR, f"{audio_id}_original.ogg")
        if message.voice:
            file = await message.voice.get_file()
        elif message.audio:
            file = await message.audio.get_file()
        else:
            await message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª.")
            return
        processor = AudioProcessor()
        if not await processor.download_audio(file.file_path, original_file):
            await message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞—É–¥–∏–æ.")
            return
        
        await message.reply_text("üîç –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å...")
        recognizer = SpeechRecognizer()
        transcript = await recognizer.recognize(original_file)
        if not transcript:
            await message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            return
        logger.info(f"Transcript for user {user.id}: {transcript[:100]}...")
        await message.reply_text("ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ...")
        analyzer = MeetingAnalyzer()
        summary = await analyzer.analyze_meeting(transcript)
        response_text = f"üìã **–ê–Ω–∞–ª–∏–∑ –≤—Å—Ç—Ä–µ—á–∏**\n\n{summary}"
        if len(response_text) > 4000:
            parts = [response_text[i:i+4000] for i in range(0, len(response_text), 4000)]
            for part in parts:
                await message.reply_text(part, parse_mode='Markdown')
        else:
            await message.reply_text(response_text, parse_mode='Markdown')
        transcript_preview = transcript[:500] + "..." if len(transcript) > 500 else transcript
        await message.reply_text(
            f"üìù **–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ñ—Ä–∞–≥–º–µ–Ω—Ç):**\n\n{transcript_preview}",
            parse_mode='Markdown'
        )
        await cleanup_files([original_file])
    except Exception as e:
        logger.error(f"Error processing audio: {e}")
        await message.reply_text("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")


async def cleanup_files(file_paths):
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
        except Exception as e:
            logger.error(f"Error removing file {file_path}: {e}")


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_text = """
üé§ **–ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –≤—Å—Ç—Ä–µ—á**

–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–ª–∏ —Ç–µ–∫—Å—Ç —Å –∑–∞–ø–∏—Å—å—é –≤—Å—Ç—Ä–µ—á–∏, –∏ —è:
1. üéµ –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å —á–µ—Ä–µ–∑ SaluteSpeech (–ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ)
2. ü§ñ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Mistral AI
3. üìã –°–æ–∑–¥–∞–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ –≤—Å—Ç—Ä–µ—á–∏

**–ß—Ç–æ —è –≤—ã–¥–µ–ª—è—é:**
‚Ä¢ –£—á–∞—Å—Ç–Ω–∏–∫–∏ –≤—Å—Ç—Ä–µ—á–∏
‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è
‚Ä¢ –ü—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è
‚Ä¢ –ù–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
‚Ä¢ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–ª–∏ —Ç–µ–∫—Å—Ç –∏ –ø–æ–ª—É—á–∏—Ç–µ –∞–Ω–∞–ª–∏–∑!
    """
    await update.message.reply_text(welcome_text, parse_mode='Markdown')


async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    message = update.message
    text = message.text.strip()
    
    await message.reply_text("üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à —Ç–µ–∫—Å—Ç...")
    try:
        logger.info(f"Text received from user {user.id}: {text[:100]}...")
        await message.reply_text("ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ...")
        analyzer = MeetingAnalyzer()
        summary = await analyzer.analyze_meeting(text)
        response_text = f"üìã **–ê–Ω–∞–ª–∏–∑ –≤—Å—Ç—Ä–µ—á–∏**\n\n{summary}"
        if len(response_text) > 4000:
            parts = [response_text[i:i+4000] for i in range(0, len(response_text), 4000)]
            for part in parts:
                await message.reply_text(part, parse_mode='Markdown')
        else:
            await message.reply_text(response_text, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"Error processing text: {e}")
        await message.reply_text("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = """
üìã **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ—Ç–∞:**

1. **–ó–∞–ø–∏—Å—å –≤—Å—Ç—Ä–µ—á–∏**: –ó–∞–ø–∏—à–∏—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º—è –≤—Å—Ç—Ä–µ—á–∏
2. **–û—Ç–ø—Ä–∞–≤–∫–∞**: –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç –±–æ—Ç—É
3. **–û–±—Ä–∞–±–æ—Ç–∫–∞**: –ë–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
   - –†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å (–ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ)
   - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —á–µ—Ä–µ–∑ AI
   - –°–æ–∑–¥–∞—Å—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
‚Ä¢ –ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
‚Ä¢ –ê—É–¥–∏–æ —Ñ–∞–π–ª—ã (MP3, OGG, WAV)
‚Ä¢ –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–¥–ª—è –ø—Ä—è–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)

**–°–æ–≤–µ—Ç—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞:**
‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç–µ —á–µ—Ç–∫–æ –∏ —Ä–∞–∑–±–æ—Ä—á–∏–≤–æ
‚Ä¢ –ò–∑–±–µ–≥–∞–π—Ç–µ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞
‚Ä¢ –ó–∞–ø–∏—Å—ã–≤–∞–π—Ç–µ –≤ —Ç–∏—Ö–æ–º –ø–æ–º–µ—â–µ–Ω–∏–∏
    """
    await update.message.reply_text(help_text, parse_mode='Markdown')


def main():
    required_vars = ['TELEGRAM_TOKEN', 'MISTRAL_API_KEY', 'SALUTE_SPEECH_AUTH_KEY']
    for var in required_vars:
        if not getattr(Config, var, None):
            logger.error(f"‚ùå {var} –Ω–µ —É–∫–∞–∑–∞–Ω –≤ .env —Ñ–∞–π–ª–µ")
            return
    application = Application.builder().token(Config.TELEGRAM_TOKEN).build()
    application.add_handler(MessageHandler(
        filters.VOICE | filters.AUDIO,
        handle_audio_message
    ))
    application.add_handler(MessageHandler(
        filters.TEXT & ~filters.COMMAND,
        handle_text_message
    ))
    from telegram.ext import CommandHandler
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    print("ü§ñ –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –≤—Å—Ç—Ä–µ—á –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == '__main__':
    main()
